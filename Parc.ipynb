{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Optional, Dict, Tuple\n",
    "from ptflops import get_model_complexity_info\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pdb\n",
    "from torch import nn\n",
    "from thop import profile\n",
    "import torchsummary\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# model_name = 'micronet_m2'\n",
    "# model = MicroNet(cfg_m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel wise attention\n",
    "class CA_layer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(CA_layer, self).__init__()\n",
    "        # global average pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel//reduction, kernel_size=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channel//reduction),\n",
    "            nn.Hardswish(),\n",
    "            nn.Conv2d(channel//reduction, channel, kernel_size=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channel),\n",
    "            nn.Hardsigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc(self.gap(x))\n",
    "        return x*y.expand_as(x)\n",
    "class gcc_ca_mf_block(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 meta_kernel_size: int,\n",
    "                 instance_kernel_method='crop',\n",
    "                 use_pe:Optional[bool]=True,\n",
    "                 mid_mix: Optional[bool]=True,\n",
    "                 bias: Optional[bool]=True,\n",
    "                 ffn_dim: Optional[int]=2,\n",
    "                 ffn_dropout=0.0,\n",
    "                 dropout=0.1):\n",
    "\n",
    "        super(gcc_ca_mf_block, self).__init__()\n",
    "\n",
    "        # spatial part,\n",
    "        self.pre_Norm_1 = nn.BatchNorm2d(num_features=dim)\n",
    "        self.pre_Norm_2 = nn.BatchNorm2d(num_features=dim)\n",
    "\n",
    "        self.meta_kernel_1_H = nn.Conv2d(dim, dim, (meta_kernel_size, 1), groups=dim).weight\n",
    "        self.meta_kernel_1_W = nn.Conv2d(dim, dim, (1, meta_kernel_size), groups=dim).weight\n",
    "        self.meta_kernel_2_H = nn.Conv2d(dim, dim, (meta_kernel_size, 1), groups=dim).weight\n",
    "        self.meta_kernel_2_W = nn.Conv2d(dim, dim, (1, meta_kernel_size), groups=dim).weight\n",
    "\n",
    "        if bias:\n",
    "            self.meta_1_H_bias = nn.Parameter(torch.randn(dim))\n",
    "            self.meta_1_W_bias = nn.Parameter(torch.randn(dim))\n",
    "            self.meta_2_H_bias = nn.Parameter(torch.randn(dim))\n",
    "            self.meta_2_W_bias = nn.Parameter(torch.randn(dim))\n",
    "        else:\n",
    "            self.meta_1_H_bias = None\n",
    "            self.meta_1_W_bias = None\n",
    "            self.meta_2_H_bias = None\n",
    "            self.meta_2_W_bias = None\n",
    "\n",
    "        self.instance_kernel_method = instance_kernel_method\n",
    "\n",
    "        if use_pe:\n",
    "            self.meta_pe_1_H = nn.Parameter(torch.randn(1, dim, meta_kernel_size, 1))\n",
    "            self.meta_pe_1_W = nn.Parameter(torch.randn(1, dim, 1, meta_kernel_size))\n",
    "            self.meta_pe_2_H = nn.Parameter(torch.randn(1, dim, meta_kernel_size, 1))\n",
    "            self.meta_pe_2_W = nn.Parameter(torch.randn(1, dim, 1, meta_kernel_size))\n",
    "\n",
    "\n",
    "        if mid_mix:\n",
    "            self.mixer = nn.ChannelShuffle(groups=2)\n",
    "\n",
    "        self.mid_mix = mid_mix\n",
    "        self.use_pe = use_pe\n",
    "        self.dim = dim\n",
    "\n",
    "        # channel part\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=2*dim),\n",
    "            nn.Conv2d(2*dim, ffn_dim, kernel_size=(1, 1), bias=True),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=ffn_dropout),\n",
    "            nn.Conv2d(ffn_dim, 2*dim, kernel_size=(1, 1), bias=True),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.ca = CA_layer(channel=2*dim)\n",
    "\n",
    "    def get_instance_kernel(self, instance_kernel_size):\n",
    "        if self.instance_kernel_method == 'crop':\n",
    "            return self.meta_kernel_1_H[:, :, : instance_kernel_size,:], \\\n",
    "                   self.meta_kernel_1_W[:, :, :, :instance_kernel_size], \\\n",
    "                   self.meta_kernel_2_H[:, :, :instance_kernel_size, :], \\\n",
    "                   self.meta_kernel_2_W[:, :, :, :instance_kernel_size]\n",
    "\n",
    "        elif self.instance_kernel_method == 'interpolation_bilinear':\n",
    "            H_shape = [instance_kernel_size, 1]\n",
    "            W_shape = [1, instance_kernel_size]\n",
    "            return F.interpolate(self.meta_kernel_1_H, H_shape, mode='bilinear', align_corners=True), \\\n",
    "                   F.interpolate(self.meta_kernel_1_W, W_shape, mode='bilinear', align_corners=True), \\\n",
    "                   F.interpolate(self.meta_kernel_2_H, H_shape, mode='bilinear', align_corners=True), \\\n",
    "                   F.interpolate(self.meta_kernel_2_W, W_shape, mode='bilinear', align_corners=True),\n",
    "\n",
    "        else:\n",
    "            print('{} is not supported!'.format(self.instance_kernel_method))\n",
    "\n",
    "    def get_instance_pe(self, instance_kernel_size):\n",
    "        if self.instance_kernel_method == 'crop':\n",
    "            return self.meta_pe_1_H[:, :, :instance_kernel_size, :]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   self.meta_pe_1_W[:, :, :, :instance_kernel_size]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   self.meta_pe_2_H[:, :, :instance_kernel_size, :]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   self.meta_pe_2_W[:, :, :, :instance_kernel_size]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size)\n",
    "\n",
    "        elif self.instance_kernel_method == 'interpolation_bilinear':\n",
    "            return F.interpolate(self.meta_pe_1_H, [instance_kernel_size, 1], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   F.interpolate(self.meta_pe_1_W, [1, instance_kernel_size], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   F.interpolate(self.meta_pe_2_H, [instance_kernel_size, 1], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   F.interpolate(self.meta_pe_2_W, [1, instance_kernel_size], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size)\n",
    "        else:\n",
    "            print('{} is not supported!'.format(self.instance_kernel_method))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x_1, x_2 = torch.chunk(x, 2, 1)\n",
    "        x_1_res, x_2_res = x_1, x_2\n",
    "        _, _, f_s, _ = x_1.shape\n",
    "\n",
    "        K_1_H, K_1_W, K_2_H, K_2_W = self.get_instance_kernel(f_s)\n",
    "\n",
    "        if self.use_pe:\n",
    "            pe_1_H, pe_1_W, pe_2_H, pe_2_W = self.get_instance_pe(f_s)\n",
    "\n",
    "        # **************************************************************************************************sptial part\n",
    "        # pre norm\n",
    "        if self.use_pe:\n",
    "            x_1, x_2 = x_1 + pe_1_H, x_2 + pe_1_W\n",
    "\n",
    "        x_1, x_2 = self.pre_Norm_1(x_1), self.pre_Norm_2(x_2)\n",
    "\n",
    "        # stage 1\n",
    "        x_1_1 = F.conv2d(torch.cat((x_1, x_1[:, :, :-1, :]), dim=2), weight=K_1_H, bias=self.meta_1_H_bias, padding=0,\n",
    "                         groups=self.dim)\n",
    "        x_2_1 = F.conv2d(torch.cat((x_2, x_2[:, :, :, :-1]), dim=3), weight=K_1_W, bias=self.meta_1_W_bias, padding=0,\n",
    "                         groups=self.dim)\n",
    "        if self.mid_mix:\n",
    "            mid_rep = torch.cat((x_1_1, x_2_1), dim=1)\n",
    "            x_1_1, x_2_1 = torch.chunk(self.mixer(mid_rep), chunks=2, dim=1)\n",
    "\n",
    "        if self.use_pe:\n",
    "            x_1_1, x_2_1 = x_1_1 + pe_2_W, x_2_1 + pe_2_H\n",
    "\n",
    "        # stage 2\n",
    "        x_1_2 = F.conv2d(torch.cat((x_1_1, x_1_1[:, :, :, :-1]), dim=3), weight=K_2_W, bias=self.meta_2_W_bias,\n",
    "                         padding=0, groups=self.dim)\n",
    "        x_2_2 = F.conv2d(torch.cat((x_2_1, x_2_1[:, :, :-1, :]), dim=2), weight=K_2_H, bias=self.meta_2_H_bias,\n",
    "                         padding=0, groups=self.dim)\n",
    "\n",
    "        # residual\n",
    "        x_1 = x_1_res + x_1_2\n",
    "        x_2 = x_2_res + x_2_2\n",
    "\n",
    "        # *************************************************************************************************channel part\n",
    "        x_ffn = torch.cat((x_1, x_2), dim=1)\n",
    "        x_ffn = x_ffn + self.ca(self.ffn(x_ffn))\n",
    "\n",
    "        return x_ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.gcc_ca_mf_block"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parc = gcc_ca_mf_block(16, 3, \"interpolation_bilinear\", use_pe=True, mid_mix=False, bias=None, ffn_dim=32, ffn_dropout=0.0, dropout=0.1)\n",
    "type(parc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a131218803ea04de256dcf68d0863f351f9c21059ac7f8146793fa89223f504a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
