{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Optional, Dict, Tuple\n",
    "from ptflops import get_model_complexity_info\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pdb\n",
    "from torch import nn\n",
    "from thop import profile\n",
    "import torchsummary\n",
    "from micronet.utils import cfg_m0\n",
    "from micronet.backbone import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# model_name = 'micronet_m2'\n",
    "# model = MicroNet(cfg_m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel wise attention\n",
    "class CA_layer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(CA_layer, self).__init__()\n",
    "        # global average pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel//reduction, kernel_size=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channel//reduction),\n",
    "            nn.Hardswish(),\n",
    "            nn.Conv2d(channel//reduction, channel, kernel_size=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channel),\n",
    "            nn.Hardsigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc(self.gap(x))\n",
    "        return x*y.expand_as(x)\n",
    "class gcc_ca_mf_block(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 meta_kernel_size: int,\n",
    "                 instance_kernel_method='crop',\n",
    "                 use_pe:Optional[bool]=True,\n",
    "                 mid_mix: Optional[bool]=True,\n",
    "                 bias: Optional[bool]=True,\n",
    "                 ffn_dim: Optional[int]=2,\n",
    "                 ffn_dropout=0.0,\n",
    "                 dropout=0.1):\n",
    "\n",
    "        super(gcc_ca_mf_block, self).__init__()\n",
    "\n",
    "        # spatial part,\n",
    "        self.pre_Norm_1 = nn.BatchNorm2d(num_features=dim)\n",
    "        self.pre_Norm_2 = nn.BatchNorm2d(num_features=dim)\n",
    "\n",
    "        self.meta_kernel_1_H = nn.Conv2d(dim, dim, (meta_kernel_size, 1), groups=dim).weight\n",
    "        self.meta_kernel_1_W = nn.Conv2d(dim, dim, (1, meta_kernel_size), groups=dim).weight\n",
    "        self.meta_kernel_2_H = nn.Conv2d(dim, dim, (meta_kernel_size, 1), groups=dim).weight\n",
    "        self.meta_kernel_2_W = nn.Conv2d(dim, dim, (1, meta_kernel_size), groups=dim).weight\n",
    "\n",
    "        if bias:\n",
    "            self.meta_1_H_bias = nn.Parameter(torch.randn(dim))\n",
    "            self.meta_1_W_bias = nn.Parameter(torch.randn(dim))\n",
    "            self.meta_2_H_bias = nn.Parameter(torch.randn(dim))\n",
    "            self.meta_2_W_bias = nn.Parameter(torch.randn(dim))\n",
    "        else:\n",
    "            self.meta_1_H_bias = None\n",
    "            self.meta_1_W_bias = None\n",
    "            self.meta_2_H_bias = None\n",
    "            self.meta_2_W_bias = None\n",
    "\n",
    "        self.instance_kernel_method = instance_kernel_method\n",
    "\n",
    "        if use_pe:\n",
    "            self.meta_pe_1_H = nn.Parameter(torch.randn(1, dim, meta_kernel_size, 1))\n",
    "            self.meta_pe_1_W = nn.Parameter(torch.randn(1, dim, 1, meta_kernel_size))\n",
    "            self.meta_pe_2_H = nn.Parameter(torch.randn(1, dim, meta_kernel_size, 1))\n",
    "            self.meta_pe_2_W = nn.Parameter(torch.randn(1, dim, 1, meta_kernel_size))\n",
    "\n",
    "\n",
    "        if mid_mix:\n",
    "            self.mixer = nn.ChannelShuffle(groups=2)\n",
    "\n",
    "        self.mid_mix = mid_mix\n",
    "        self.use_pe = use_pe\n",
    "        self.dim = dim\n",
    "\n",
    "        # channel part\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=2*dim),\n",
    "            nn.Conv2d(2*dim, ffn_dim, kernel_size=(1, 1), bias=True),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=ffn_dropout),\n",
    "            nn.Conv2d(ffn_dim, 2*dim, kernel_size=(1, 1), bias=True),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.ca = CA_layer(channel=2*dim)\n",
    "\n",
    "    def get_instance_kernel(self, instance_kernel_size):\n",
    "        if self.instance_kernel_method == 'crop':\n",
    "            return self.meta_kernel_1_H[:, :, : instance_kernel_size,:], \\\n",
    "                   self.meta_kernel_1_W[:, :, :, :instance_kernel_size], \\\n",
    "                   self.meta_kernel_2_H[:, :, :instance_kernel_size, :], \\\n",
    "                   self.meta_kernel_2_W[:, :, :, :instance_kernel_size]\n",
    "\n",
    "        elif self.instance_kernel_method == 'interpolation_bilinear':\n",
    "            H_shape = [instance_kernel_size, 1]\n",
    "            W_shape = [1, instance_kernel_size]\n",
    "            return F.interpolate(self.meta_kernel_1_H, H_shape, mode='bilinear', align_corners=True), \\\n",
    "                   F.interpolate(self.meta_kernel_1_W, W_shape, mode='bilinear', align_corners=True), \\\n",
    "                   F.interpolate(self.meta_kernel_2_H, H_shape, mode='bilinear', align_corners=True), \\\n",
    "                   F.interpolate(self.meta_kernel_2_W, W_shape, mode='bilinear', align_corners=True),\n",
    "\n",
    "        else:\n",
    "            print('{} is not supported!'.format(self.instance_kernel_method))\n",
    "\n",
    "    def get_instance_pe(self, instance_kernel_size):\n",
    "        if self.instance_kernel_method == 'crop':\n",
    "            return self.meta_pe_1_H[:, :, :instance_kernel_size, :]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   self.meta_pe_1_W[:, :, :, :instance_kernel_size]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   self.meta_pe_2_H[:, :, :instance_kernel_size, :]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   self.meta_pe_2_W[:, :, :, :instance_kernel_size]\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size)\n",
    "\n",
    "        elif self.instance_kernel_method == 'interpolation_bilinear':\n",
    "            return F.interpolate(self.meta_pe_1_H, [instance_kernel_size, 1], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   F.interpolate(self.meta_pe_1_W, [1, instance_kernel_size], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   F.interpolate(self.meta_pe_2_H, [instance_kernel_size, 1], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size), \\\n",
    "                   F.interpolate(self.meta_pe_2_W, [1, instance_kernel_size], mode='bilinear', align_corners=True)\\\n",
    "                       .expand(1, self.dim, instance_kernel_size, instance_kernel_size)\n",
    "        else:\n",
    "            print('{} is not supported!'.format(self.instance_kernel_method))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x_1, x_2 = torch.chunk(x, 2, 1)\n",
    "        x_1_res, x_2_res = x_1, x_2\n",
    "        _, _, f_s, _ = x_1.shape\n",
    "\n",
    "        K_1_H, K_1_W, K_2_H, K_2_W = self.get_instance_kernel(f_s)\n",
    "\n",
    "        if self.use_pe:\n",
    "            pe_1_H, pe_1_W, pe_2_H, pe_2_W = self.get_instance_pe(f_s)\n",
    "\n",
    "        # **************************************************************************************************sptial part\n",
    "        # pre norm\n",
    "        if self.use_pe:\n",
    "            x_1, x_2 = x_1 + pe_1_H, x_2 + pe_1_W\n",
    "\n",
    "        x_1, x_2 = self.pre_Norm_1(x_1), self.pre_Norm_2(x_2)\n",
    "\n",
    "        # stage 1\n",
    "        x_1_1 = F.conv2d(torch.cat((x_1, x_1[:, :, :-1, :]), dim=2), weight=K_1_H, bias=self.meta_1_H_bias, padding=0,\n",
    "                         groups=self.dim)\n",
    "        x_2_1 = F.conv2d(torch.cat((x_2, x_2[:, :, :, :-1]), dim=3), weight=K_1_W, bias=self.meta_1_W_bias, padding=0,\n",
    "                         groups=self.dim)\n",
    "        if self.mid_mix:\n",
    "            mid_rep = torch.cat((x_1_1, x_2_1), dim=1)\n",
    "            x_1_1, x_2_1 = torch.chunk(self.mixer(mid_rep), chunks=2, dim=1)\n",
    "\n",
    "        if self.use_pe:\n",
    "            x_1_1, x_2_1 = x_1_1 + pe_2_W, x_2_1 + pe_2_H\n",
    "\n",
    "        # stage 2\n",
    "        x_1_2 = F.conv2d(torch.cat((x_1_1, x_1_1[:, :, :, :-1]), dim=3), weight=K_2_W, bias=self.meta_2_W_bias,\n",
    "                         padding=0, groups=self.dim)\n",
    "        x_2_2 = F.conv2d(torch.cat((x_2_1, x_2_1[:, :, :-1, :]), dim=2), weight=K_2_H, bias=self.meta_2_H_bias,\n",
    "                         padding=0, groups=self.dim)\n",
    "\n",
    "        # residual\n",
    "        x_1 = x_1_res + x_1_2\n",
    "        x_2 = x_2_res + x_2_2\n",
    "\n",
    "        # *************************************************************************************************channel part\n",
    "        x_ffn = torch.cat((x_1, x_2), dim=1)\n",
    "        x_ffn = x_ffn + self.ca(self.ffn(x_ffn))\n",
    "\n",
    "        return x_ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gcc_ca_mf_block(32, 12, 'interpolation_bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(torch.randn(10, 64, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block: 12544, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "block: 3136, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 12, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 12, token: 128\n",
      "block: 3136, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 12, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 24, token: 128\n",
      "block: 784, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 24, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 24, token: 128\n",
      "block: 784, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 24, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 48, token: 128\n",
      "block: 196, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 48, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 48, token: 128\n",
      "block: 196, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 48, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 64, token: 128\n",
      "block: 196, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 64, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 96, token: 128\n",
      "block: 49, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 96, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 96, token: 128\n",
      "L2G: 2 heads, inp: 96, token: 128\n"
     ]
    }
   ],
   "source": [
    "model_name = 'micro_former_shift_26m'\n",
    "model = timm.create_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'mobile_former_26m_micro_m0'\n",
    "# model = timm.create_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block: 12544, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "block: 3136, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 12, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 12, token: 128\n",
      "block: 3136, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 12, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 24, token: 128\n",
      "block: 784, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 24, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 24, token: 128\n",
      "block: 784, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 24, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 48, token: 128\n",
      "block: 196, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 48, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 48, token: 128\n",
      "block: 196, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 48, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 64, token: 128\n",
      "block: 196, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 64, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 96, token: 128\n",
      "block: 49, cnn-drop 0.0000, mlp-drop 0.0000\n",
      "L2G: 2 heads, inp: 96, token: 128\n",
      "G2G: 4 heads\n",
      "use ffn\n",
      "G2L: 2 heads, inp: 96, token: 128\n",
      "L2G: 2 heads, inp: 96, token: 128\n",
      "MobileFormer(\n",
      "  (tokens): Embedding(3, 128)\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (features): Sequential(\n",
      "    (0): DnaBlock3(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(8, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): ChannelShuffle()\n",
      "        (4): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DnaBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=72, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)\n",
      "        (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper2): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=72, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=12, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=12, bias=True)\n",
      "        (proj): Linear(in_features=12, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=12, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=12, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (2): DnaBlock3(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(12, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=12, bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=144, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=192, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act4): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper4): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=12, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=12, bias=True)\n",
      "        (proj): Linear(in_features=12, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=24, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=24, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (3): DnaBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=144, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper2): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=144, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=24, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=24, bias=True)\n",
      "        (proj): Linear(in_features=24, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=24, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=24, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (4): DnaBlock3(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=288, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=384, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act4): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper4): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=24, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=24, bias=True)\n",
      "        (proj): Linear(in_features=24, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=48, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=48, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (5): DnaBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=384, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper2): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=384, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=48, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=48, bias=True)\n",
      "        (proj): Linear(in_features=48, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=48, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=48, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (6): DnaBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=576, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper2): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=576, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=48, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=48, bias=True)\n",
      "        (proj): Linear(in_features=48, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (7): DnaBlock3(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=768, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=768, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act4): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper4): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (proj): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "    (8): DnaBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act1): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper1): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=1152, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (act2): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper2): HyperFunc(\n",
      "        (hyper): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=1152, bias=True)\n",
      "          (3): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ChannelShuffle()\n",
      "      )\n",
      "      (act3): DyReLU(\n",
      "        (act): Sequential()\n",
      "      )\n",
      "      (hyper3): Sequential()\n",
      "      (drop_path): DropPath(drop_prob=0.000)\n",
      "      (local_global): Local2Global(\n",
      "        (alpha): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "          (1): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (q): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (proj): Linear(in_features=96, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_block): GlobalBlock(\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): GELU(approximate=none)\n",
      "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (channel_mlp): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "      (global_local): Global2Local(\n",
      "        (k): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (drop_path): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (local_global): Local2Global(\n",
      "    (alpha): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "      (1): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (q): Linear(in_features=128, out_features=96, bias=True)\n",
      "    (proj): Linear(in_features=96, out_features=128, bias=True)\n",
      "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (drop_path): DropPath(drop_prob=0.000)\n",
      "  )\n",
      "  (classifier): MergeClassifier(\n",
      "    (conv): Sequential(\n",
      "      (0): ChannelShuffle()\n",
      "      (1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
      "      (2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (act): DyReLU(\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (hyper): Sequential()\n",
      "    (avgpool): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (1): h_swish(\n",
      "        (sigmoid): h_sigmoid(\n",
      "          (relu): ReLU6(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=704, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): h_swish(\n",
      "        (sigmoid): h_sigmoid(\n",
      "          (relu): ReLU6(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "      (1): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mobile_former_26m'\n",
    "model = timm.create_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilevitv2_050'\n",
    "model = timm.create_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 6, 224, 224)\n",
    "macs, params, layer_info = profile(model, inputs=(input, ), ret_layer_info=True)\n",
    "print(model_name, macs/1e6)\n",
    "# mobile_former_294m 293.074048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Identity is treated as a zero-op.\n",
      "Warning: module SiLU is treated as a zero-op.\n",
      "Warning: module BatchNormAct2d is treated as a zero-op.\n",
      "Warning: module ConvNormAct is treated as a zero-op.\n",
      "Warning: module BottleneckBlock is treated as a zero-op.\n",
      "Warning: module GroupNorm1 is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module LinearSelfAttention is treated as a zero-op.\n",
      "Warning: module DropPath is treated as a zero-op.\n",
      "Warning: module ConvMlp is treated as a zero-op.\n",
      "Warning: module LinearTransformerBlock is treated as a zero-op.\n",
      "Warning: module MobileVitV2Block is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Warning: module SelectAdaptivePool2d is treated as a zero-op.\n",
      "Warning: module ClassifierHead is treated as a zero-op.\n",
      "Warning: module ByobNet is treated as a zero-op.\n",
      "ByobNet(\n",
      "  1.36 M, 99.129% Params, 363.17 MMac, 100.000% MACs, \n",
      "  (stem): ConvNormAct(\n",
      "    432, 0.032% Params, 5.42 MMac, 1.492% MACs, \n",
      "    (conv): Conv2d(432, 0.032% Params, 5.42 MMac, 1.492% MACs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNormAct2d(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    1.1 M, 80.347% Params, 357.48 MMac, 98.433% MACs, \n",
      "    (0): Sequential(\n",
      "      1.82 k, 0.133% Params, 22.88 MMac, 6.300% MACs, \n",
      "      (0): BottleneckBlock(\n",
      "        1.82 k, 0.133% Params, 22.88 MMac, 6.300% MACs, \n",
      "        (conv1_1x1): ConvNormAct(\n",
      "          512, 0.037% Params, 6.42 MMac, 1.768% MACs, \n",
      "          (conv): Conv2d(512, 0.037% Params, 6.42 MMac, 1.768% MACs, 16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2_kxk): ConvNormAct(\n",
      "          288, 0.021% Params, 3.61 MMac, 0.995% MACs, \n",
      "          (conv): Conv2d(288, 0.021% Params, 3.61 MMac, 0.995% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2b_kxk): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (attn): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv3_1x1): ConvNormAct(\n",
      "          1.02 k, 0.075% Params, 12.85 MMac, 3.537% MACs, \n",
      "          (conv): Conv2d(1.02 k, 0.075% Params, 12.85 MMac, 3.537% MACs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "        (attn_last): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      24.26 k, 1.770% Params, 95.33 MMac, 26.251% MACs, \n",
      "      (0): BottleneckBlock(\n",
      "        6.72 k, 0.490% Params, 40.34 MMac, 11.108% MACs, \n",
      "        (conv1_1x1): ConvNormAct(\n",
      "          2.05 k, 0.149% Params, 25.69 MMac, 7.074% MACs, \n",
      "          (conv): Conv2d(2.05 k, 0.149% Params, 25.69 MMac, 7.074% MACs, 32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2_kxk): ConvNormAct(\n",
      "          576, 0.042% Params, 1.81 MMac, 0.497% MACs, \n",
      "          (conv): Conv2d(576, 0.042% Params, 1.81 MMac, 0.497% MACs, 64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2b_kxk): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (attn): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv3_1x1): ConvNormAct(\n",
      "          4.1 k, 0.299% Params, 12.85 MMac, 3.537% MACs, \n",
      "          (conv): Conv2d(4.1 k, 0.299% Params, 12.85 MMac, 3.537% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "        (attn_last): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        17.54 k, 1.279% Params, 54.99 MMac, 15.142% MACs, \n",
      "        (shortcut): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv1_1x1): ConvNormAct(\n",
      "          8.19 k, 0.598% Params, 25.69 MMac, 7.074% MACs, \n",
      "          (conv): Conv2d(8.19 k, 0.598% Params, 25.69 MMac, 7.074% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2_kxk): ConvNormAct(\n",
      "          1.15 k, 0.084% Params, 3.61 MMac, 0.995% MACs, \n",
      "          (conv): Conv2d(1.15 k, 0.084% Params, 3.61 MMac, 0.995% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2b_kxk): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (attn): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv3_1x1): ConvNormAct(\n",
      "          8.19 k, 0.598% Params, 25.69 MMac, 7.074% MACs, \n",
      "          (conv): Conv2d(8.19 k, 0.598% Params, 25.69 MMac, 7.074% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "        (attn_last): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      101.51 k, 7.406% Params, 98.85 MMac, 27.218% MACs, \n",
      "      (0): BottleneckBlock(\n",
      "        25.73 k, 1.877% Params, 39.44 MMac, 10.859% MACs, \n",
      "        (conv1_1x1): ConvNormAct(\n",
      "          8.19 k, 0.598% Params, 25.69 MMac, 7.074% MACs, \n",
      "          (conv): Conv2d(8.19 k, 0.598% Params, 25.69 MMac, 7.074% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2_kxk): ConvNormAct(\n",
      "          1.15 k, 0.084% Params, 903.17 KMac, 0.249% MACs, \n",
      "          (conv): Conv2d(1.15 k, 0.084% Params, 903.17 KMac, 0.249% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2b_kxk): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (attn): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv3_1x1): ConvNormAct(\n",
      "          16.38 k, 1.195% Params, 12.85 MMac, 3.537% MACs, \n",
      "          (conv): Conv2d(16.38 k, 1.195% Params, 12.85 MMac, 3.537% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "        (attn_last): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "      (1): MobileVitV2Block(\n",
      "        75.78 k, 5.529% Params, 59.41 MMac, 16.359% MACs, \n",
      "        (conv_kxk): ConvNormAct(\n",
      "          1.15 k, 0.084% Params, 903.17 KMac, 0.249% MACs, \n",
      "          (conv): Conv2d(1.15 k, 0.084% Params, 903.17 KMac, 0.249% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv_1x1): Conv2d(8.19 k, 0.598% Params, 6.42 MMac, 1.768% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (transformer): Sequential(\n",
      "          58.24 k, 4.249% Params, 45.66 MMac, 12.573% MACs, \n",
      "          (0): LinearTransformerBlock(\n",
      "            29.12 k, 2.125% Params, 22.83 MMac, 6.287% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 64, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              12.54 k, 0.915% Params, 9.84 MMac, 2.708% MACs, \n",
      "              (qkv_proj): Conv2d(8.38 k, 0.612% Params, 6.57 MMac, 1.810% MACs, 64, 129, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(4.16 k, 0.304% Params, 3.26 MMac, 0.898% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 64, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              16.58 k, 1.209% Params, 13.0 MMac, 3.578% MACs, \n",
      "              (fc1): Conv2d(8.32 k, 0.607% Params, 6.52 MMac, 1.796% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(8.26 k, 0.602% Params, 6.47 MMac, 1.782% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "          (1): LinearTransformerBlock(\n",
      "            29.12 k, 2.125% Params, 22.83 MMac, 6.287% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 64, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              12.54 k, 0.915% Params, 9.84 MMac, 2.708% MACs, \n",
      "              (qkv_proj): Conv2d(8.38 k, 0.612% Params, 6.57 MMac, 1.810% MACs, 64, 129, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(4.16 k, 0.304% Params, 3.26 MMac, 0.898% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 64, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              16.58 k, 1.209% Params, 13.0 MMac, 3.578% MACs, \n",
      "              (fc1): Conv2d(8.32 k, 0.607% Params, 6.52 MMac, 1.796% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(8.26 k, 0.602% Params, 6.47 MMac, 1.782% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "        )\n",
      "        (norm): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 64, eps=1e-05, affine=True)\n",
      "        (conv_proj): ConvNormAct(\n",
      "          8.19 k, 0.598% Params, 6.42 MMac, 1.768% MACs, \n",
      "          (conv): Conv2d(8.19 k, 0.598% Params, 6.42 MMac, 1.768% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      383.56 k, 27.985% Params, 94.44 MMac, 26.006% MACs, \n",
      "      (0): BottleneckBlock(\n",
      "        84.22 k, 6.145% Params, 35.78 MMac, 9.851% MACs, \n",
      "        (conv1_1x1): ConvNormAct(\n",
      "          32.77 k, 2.391% Params, 25.69 MMac, 7.074% MACs, \n",
      "          (conv): Conv2d(32.77 k, 2.391% Params, 25.69 MMac, 7.074% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2_kxk): ConvNormAct(\n",
      "          2.3 k, 0.168% Params, 451.58 KMac, 0.124% MACs, \n",
      "          (conv): Conv2d(2.3 k, 0.168% Params, 451.58 KMac, 0.124% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2b_kxk): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (attn): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv3_1x1): ConvNormAct(\n",
      "          49.15 k, 3.586% Params, 9.63 MMac, 2.653% MACs, \n",
      "          (conv): Conv2d(49.15 k, 3.586% Params, 9.63 MMac, 2.653% MACs, 256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "        (attn_last): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "      (1): MobileVitV2Block(\n",
      "        299.33 k, 21.840% Params, 58.67 MMac, 16.155% MACs, \n",
      "        (conv_kxk): ConvNormAct(\n",
      "          1.73 k, 0.126% Params, 338.69 KMac, 0.093% MACs, \n",
      "          (conv): Conv2d(1.73 k, 0.126% Params, 338.69 KMac, 0.093% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv_1x1): Conv2d(18.43 k, 1.345% Params, 3.61 MMac, 0.995% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (transformer): Sequential(\n",
      "          260.74 k, 19.024% Params, 51.11 MMac, 14.072% MACs, \n",
      "          (0): LinearTransformerBlock(\n",
      "            65.19 k, 4.756% Params, 12.78 MMac, 3.518% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              28.03 k, 2.045% Params, 5.49 MMac, 1.513% MACs, \n",
      "              (qkv_proj): Conv2d(18.72 k, 1.366% Params, 3.67 MMac, 1.010% MACs, 96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(9.31 k, 0.679% Params, 1.83 MMac, 0.503% MACs, 96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              37.15 k, 2.711% Params, 7.28 MMac, 2.005% MACs, \n",
      "              (fc1): Conv2d(18.62 k, 1.359% Params, 3.65 MMac, 1.005% MACs, 96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(18.53 k, 1.352% Params, 3.63 MMac, 1.000% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "          (1): LinearTransformerBlock(\n",
      "            65.19 k, 4.756% Params, 12.78 MMac, 3.518% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              28.03 k, 2.045% Params, 5.49 MMac, 1.513% MACs, \n",
      "              (qkv_proj): Conv2d(18.72 k, 1.366% Params, 3.67 MMac, 1.010% MACs, 96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(9.31 k, 0.679% Params, 1.83 MMac, 0.503% MACs, 96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              37.15 k, 2.711% Params, 7.28 MMac, 2.005% MACs, \n",
      "              (fc1): Conv2d(18.62 k, 1.359% Params, 3.65 MMac, 1.005% MACs, 96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(18.53 k, 1.352% Params, 3.63 MMac, 1.000% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "          (2): LinearTransformerBlock(\n",
      "            65.19 k, 4.756% Params, 12.78 MMac, 3.518% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              28.03 k, 2.045% Params, 5.49 MMac, 1.513% MACs, \n",
      "              (qkv_proj): Conv2d(18.72 k, 1.366% Params, 3.67 MMac, 1.010% MACs, 96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(9.31 k, 0.679% Params, 1.83 MMac, 0.503% MACs, 96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              37.15 k, 2.711% Params, 7.28 MMac, 2.005% MACs, \n",
      "              (fc1): Conv2d(18.62 k, 1.359% Params, 3.65 MMac, 1.005% MACs, 96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(18.53 k, 1.352% Params, 3.63 MMac, 1.000% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "          (3): LinearTransformerBlock(\n",
      "            65.19 k, 4.756% Params, 12.78 MMac, 3.518% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              28.03 k, 2.045% Params, 5.49 MMac, 1.513% MACs, \n",
      "              (qkv_proj): Conv2d(18.72 k, 1.366% Params, 3.67 MMac, 1.010% MACs, 96, 193, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(9.31 k, 0.679% Params, 1.83 MMac, 0.503% MACs, 96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              37.15 k, 2.711% Params, 7.28 MMac, 2.005% MACs, \n",
      "              (fc1): Conv2d(18.62 k, 1.359% Params, 3.65 MMac, 1.005% MACs, 96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(18.53 k, 1.352% Params, 3.63 MMac, 1.000% MACs, 192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "        )\n",
      "        (norm): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 96, eps=1e-05, affine=True)\n",
      "        (conv_proj): ConvNormAct(\n",
      "          18.43 k, 1.345% Params, 3.61 MMac, 0.995% MACs, \n",
      "          (conv): Conv2d(18.43 k, 1.345% Params, 3.61 MMac, 0.995% MACs, 96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      590.08 k, 43.053% Params, 45.97 MMac, 12.658% MACs, \n",
      "      (0): BottleneckBlock(\n",
      "        175.49 k, 12.804% Params, 19.44 MMac, 5.352% MACs, \n",
      "        (conv1_1x1): ConvNormAct(\n",
      "          73.73 k, 5.379% Params, 14.45 MMac, 3.979% MACs, \n",
      "          (conv): Conv2d(73.73 k, 5.379% Params, 14.45 MMac, 3.979% MACs, 192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2_kxk): ConvNormAct(\n",
      "          3.46 k, 0.252% Params, 169.34 KMac, 0.047% MACs, \n",
      "          (conv): Conv2d(3.46 k, 0.252% Params, 169.34 KMac, 0.047% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2b_kxk): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (attn): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (conv3_1x1): ConvNormAct(\n",
      "          98.3 k, 7.172% Params, 4.82 MMac, 1.326% MACs, \n",
      "          (conv): Conv2d(98.3 k, 7.172% Params, 4.82 MMac, 1.326% MACs, 384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "        (attn_last): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "      (1): MobileVitV2Block(\n",
      "        414.6 k, 30.249% Params, 26.53 MMac, 7.306% MACs, \n",
      "        (conv_kxk): ConvNormAct(\n",
      "          2.3 k, 0.168% Params, 147.46 KMac, 0.041% MACs, \n",
      "          (conv): Conv2d(2.3 k, 0.168% Params, 147.46 KMac, 0.041% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv_1x1): Conv2d(32.77 k, 2.391% Params, 2.1 MMac, 0.577% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (transformer): Sequential(\n",
      "          346.75 k, 25.300% Params, 22.19 MMac, 6.111% MACs, \n",
      "          (0): LinearTransformerBlock(\n",
      "            115.58 k, 8.433% Params, 7.4 MMac, 2.037% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              49.66 k, 3.624% Params, 3.18 MMac, 0.875% MACs, \n",
      "              (qkv_proj): Conv2d(33.15 k, 2.419% Params, 2.12 MMac, 0.584% MACs, 128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(16.51 k, 1.205% Params, 1.06 MMac, 0.291% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              65.92 k, 4.810% Params, 4.22 MMac, 1.162% MACs, \n",
      "              (fc1): Conv2d(33.02 k, 2.409% Params, 2.11 MMac, 0.582% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(32.9 k, 2.400% Params, 2.11 MMac, 0.580% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "          (1): LinearTransformerBlock(\n",
      "            115.58 k, 8.433% Params, 7.4 MMac, 2.037% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              49.66 k, 3.624% Params, 3.18 MMac, 0.875% MACs, \n",
      "              (qkv_proj): Conv2d(33.15 k, 2.419% Params, 2.12 MMac, 0.584% MACs, 128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(16.51 k, 1.205% Params, 1.06 MMac, 0.291% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              65.92 k, 4.810% Params, 4.22 MMac, 1.162% MACs, \n",
      "              (fc1): Conv2d(33.02 k, 2.409% Params, 2.11 MMac, 0.582% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(32.9 k, 2.400% Params, 2.11 MMac, 0.580% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "          (2): LinearTransformerBlock(\n",
      "            115.58 k, 8.433% Params, 7.4 MMac, 2.037% MACs, \n",
      "            (norm1): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "            (attn): LinearSelfAttention(\n",
      "              49.66 k, 3.624% Params, 3.18 MMac, 0.875% MACs, \n",
      "              (qkv_proj): Conv2d(33.15 k, 2.419% Params, 2.12 MMac, 0.584% MACs, 128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (attn_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (out_proj): Conv2d(16.51 k, 1.205% Params, 1.06 MMac, 0.291% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (out_drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "            (norm2): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "            (mlp): ConvMlp(\n",
      "              65.92 k, 4.810% Params, 4.22 MMac, 1.162% MACs, \n",
      "              (fc1): Conv2d(33.02 k, 2.409% Params, 2.11 MMac, 0.582% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (norm): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (act): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "              (drop): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.0, inplace=False)\n",
      "              (fc2): Conv2d(32.9 k, 2.400% Params, 2.11 MMac, 0.580% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (drop_path2): DropPath(0, 0.000% Params, 0.0 Mac, 0.000% MACs, drop_prob=0.000)\n",
      "          )\n",
      "        )\n",
      "        (norm): GroupNorm1(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 1, 128, eps=1e-05, affine=True)\n",
      "        (conv_proj): ConvNormAct(\n",
      "          32.77 k, 2.391% Params, 2.1 MMac, 0.577% MACs, \n",
      "          (conv): Conv2d(32.77 k, 2.391% Params, 2.1 MMac, 0.577% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNormAct2d(\n",
      "            0, 0.000% Params, 0.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "            (act): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  (head): ClassifierHead(\n",
      "    257.0 k, 18.751% Params, 273.38 KMac, 0.075% MACs, \n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(257.0 k, 18.751% Params, 257.0 KMac, 0.071% MACs, in_features=256, out_features=1000, bias=True)\n",
      "    (flatten): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "Computational complexity:       363.17 MMac\n",
      "Number of parameters:           1.37 M  \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "  # net = model\n",
    "  net = model\n",
    "  macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MobileFormer                                  [1, 1000]                 --\n",
       "├─Embedding: 1-1                              --                        512\n",
       "├─Sequential: 1-2                             [1, 12, 112, 112]         --\n",
       "│    └─Conv2d: 2-1                            [1, 12, 112, 112]         324\n",
       "│    └─BatchNorm2d: 2-2                       [1, 12, 112, 112]         24\n",
       "│    └─ReLU6: 2-3                             [1, 12, 112, 112]         --\n",
       "├─Sequential: 1-3                             [1, 128, 7, 7]            --\n",
       "│    └─DnaBlock3: 2-4                         [1, 12, 112, 112]         --\n",
       "│    │    └─Sequential: 3-1                   [1, 12, 112, 112]         576\n",
       "│    └─DnaBlock3: 2-5                         [1, 16, 56, 56]           --\n",
       "│    │    └─Local2Global: 3-2                 [4, 1, 128]               5,016\n",
       "│    │    └─GlobalBlock: 3-3                  [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-4                   [1, 72, 56, 56]           792\n",
       "│    │    └─HyperFunc: 3-5                    [1, 144, 1, 1]            8,880\n",
       "│    │    └─DyReLU: 3-6                       [1, 72, 56, 56]           --\n",
       "│    │    └─Sequential: 3-7                   [1, 16, 56, 56]           1,184\n",
       "│    │    └─DyReLU: 3-8                       [1, 16, 56, 56]           --\n",
       "│    │    └─Sequential: 3-9                   [1, 64, 56, 56]           704\n",
       "│    │    └─HyperFunc: 3-10                   [1, 128, 1, 1]            8,352\n",
       "│    │    └─DyReLU: 3-11                      [1, 64, 56, 56]           --\n",
       "│    │    └─Sequential: 3-12                  [1, 16, 56, 56]           1,056\n",
       "│    │    └─DyReLU: 3-13                      [1, 16, 56, 56]           --\n",
       "│    │    └─DropPath: 3-14                    [1, 16, 56, 56]           --\n",
       "│    │    └─Global2Local: 3-15                [1, 16, 56, 56]           4,128\n",
       "│    └─DnaBlock3: 2-6                         [1, 32, 28, 28]           --\n",
       "│    │    └─Local2Global: 3-16                [4, 1, 128]               6,560\n",
       "│    │    └─GlobalBlock: 3-17                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-18                  [1, 96, 28, 28]           1,056\n",
       "│    │    └─HyperFunc: 3-19                   [1, 192, 1, 1]            10,464\n",
       "│    │    └─DyReLU: 3-20                      [1, 96, 28, 28]           --\n",
       "│    │    └─Sequential: 3-21                  [1, 32, 28, 28]           3,136\n",
       "│    │    └─DyReLU: 3-22                      [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-23                  [1, 128, 28, 28]          1,408\n",
       "│    │    └─HyperFunc: 3-24                   [1, 256, 1, 1]            12,576\n",
       "│    │    └─DyReLU: 3-25                      [1, 128, 28, 28]          --\n",
       "│    │    └─Sequential: 3-26                  [1, 32, 28, 28]           4,160\n",
       "│    │    └─DyReLU: 3-27                      [1, 32, 28, 28]           --\n",
       "│    │    └─DropPath: 3-28                    [1, 32, 28, 28]           --\n",
       "│    │    └─Global2Local: 3-29                [1, 32, 28, 28]           8,256\n",
       "│    └─DnaBlock: 2-7                          [1, 32, 28, 28]           --\n",
       "│    │    └─Local2Global: 3-30                [4, 1, 128]               12,736\n",
       "│    │    └─GlobalBlock: 3-31                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-32                  [1, 96, 28, 28]           3,264\n",
       "│    │    └─HyperFunc: 3-33                   [1, 192, 1, 1]            10,464\n",
       "│    │    └─DyReLU: 3-34                      [1, 96, 28, 28]           --\n",
       "│    │    └─Sequential: 3-35                  [1, 96, 28, 28]           1,056\n",
       "│    │    └─HyperFunc: 3-36                   [1, 192, 1, 1]            10,464\n",
       "│    │    └─DyReLU: 3-37                      [1, 96, 28, 28]           --\n",
       "│    │    └─Sequential: 3-38                  [1, 32, 28, 28]           3,136\n",
       "│    │    └─DyReLU: 3-39                      [1, 32, 28, 28]           --\n",
       "│    │    └─DropPath: 3-40                    [1, 32, 28, 28]           --\n",
       "│    │    └─Global2Local: 3-41                [1, 32, 28, 28]           8,256\n",
       "│    └─DnaBlock3: 2-8                         [1, 64, 14, 14]           --\n",
       "│    │    └─Local2Global: 3-42                [4, 1, 128]               12,736\n",
       "│    │    └─GlobalBlock: 3-43                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-44                  [1, 192, 14, 14]          2,112\n",
       "│    │    └─HyperFunc: 3-45                   [1, 384, 1, 1]            16,800\n",
       "│    │    └─DyReLU: 3-46                      [1, 192, 14, 14]          --\n",
       "│    │    └─Sequential: 3-47                  [1, 64, 14, 14]           12,416\n",
       "│    │    └─DyReLU: 3-48                      [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-49                  [1, 256, 14, 14]          2,816\n",
       "│    │    └─HyperFunc: 3-50                   [1, 512, 1, 1]            21,024\n",
       "│    │    └─DyReLU: 3-51                      [1, 256, 14, 14]          --\n",
       "│    │    └─Sequential: 3-52                  [1, 64, 14, 14]           16,512\n",
       "│    │    └─DyReLU: 3-53                      [1, 64, 14, 14]           --\n",
       "│    │    └─DropPath: 3-54                    [1, 64, 14, 14]           --\n",
       "│    │    └─Global2Local: 3-55                [1, 64, 14, 14]           16,512\n",
       "│    └─DnaBlock: 2-9                          [1, 64, 14, 14]           --\n",
       "│    │    └─Local2Global: 3-56                [4, 1, 128]               25,088\n",
       "│    │    └─GlobalBlock: 3-57                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-58                  [1, 256, 14, 14]          16,896\n",
       "│    │    └─HyperFunc: 3-59                   [1, 512, 1, 1]            21,024\n",
       "│    │    └─DyReLU: 3-60                      [1, 256, 14, 14]          --\n",
       "│    │    └─Sequential: 3-61                  [1, 256, 14, 14]          2,816\n",
       "│    │    └─HyperFunc: 3-62                   [1, 512, 1, 1]            21,024\n",
       "│    │    └─DyReLU: 3-63                      [1, 256, 14, 14]          --\n",
       "│    │    └─Sequential: 3-64                  [1, 64, 14, 14]           16,512\n",
       "│    │    └─DyReLU: 3-65                      [1, 64, 14, 14]           --\n",
       "│    │    └─DropPath: 3-66                    [1, 64, 14, 14]           --\n",
       "│    │    └─Global2Local: 3-67                [1, 64, 14, 14]           16,512\n",
       "│    └─DnaBlock: 2-10                         [1, 88, 14, 14]           --\n",
       "│    │    └─Local2Global: 3-68                [4, 1, 128]               25,088\n",
       "│    │    └─GlobalBlock: 3-69                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-70                  [1, 384, 14, 14]          25,344\n",
       "│    │    └─HyperFunc: 3-71                   [1, 768, 1, 1]            29,472\n",
       "│    │    └─DyReLU: 3-72                      [1, 384, 14, 14]          --\n",
       "│    │    └─Sequential: 3-73                  [1, 384, 14, 14]          4,224\n",
       "│    │    └─HyperFunc: 3-74                   [1, 768, 1, 1]            29,472\n",
       "│    │    └─DyReLU: 3-75                      [1, 384, 14, 14]          --\n",
       "│    │    └─Sequential: 3-76                  [1, 88, 14, 14]           33,968\n",
       "│    │    └─DyReLU: 3-77                      [1, 88, 14, 14]           --\n",
       "│    │    └─Global2Local: 3-78                [1, 88, 14, 14]           22,704\n",
       "│    └─DnaBlock3: 2-11                        [1, 128, 7, 7]            --\n",
       "│    │    └─Local2Global: 3-79                [4, 1, 128]               34,352\n",
       "│    │    └─GlobalBlock: 3-80                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-81                  [1, 528, 7, 7]            5,808\n",
       "│    │    └─HyperFunc: 3-82                   [1, 1056, 1, 1]           38,976\n",
       "│    │    └─DyReLU: 3-83                      [1, 528, 7, 7]            --\n",
       "│    │    └─Sequential: 3-84                  [1, 128, 7, 7]            67,840\n",
       "│    │    └─DyReLU: 3-85                      [1, 128, 7, 7]            --\n",
       "│    │    └─Sequential: 3-86                  [1, 512, 7, 7]            5,632\n",
       "│    │    └─HyperFunc: 3-87                   [1, 1024, 1, 1]           37,920\n",
       "│    │    └─DyReLU: 3-88                      [1, 512, 7, 7]            --\n",
       "│    │    └─Sequential: 3-89                  [1, 128, 7, 7]            65,792\n",
       "│    │    └─DyReLU: 3-90                      [1, 128, 7, 7]            --\n",
       "│    │    └─DropPath: 3-91                    [1, 128, 7, 7]            --\n",
       "│    │    └─Global2Local: 3-92                [1, 128, 7, 7]            33,024\n",
       "│    └─DnaBlock: 2-12                         [1, 128, 7, 7]            --\n",
       "│    │    └─Local2Global: 3-93                [4, 1, 128]               49,792\n",
       "│    │    └─GlobalBlock: 3-94                 [4, 1, 128]               99,456\n",
       "│    │    └─Sequential: 3-95                  [1, 768, 7, 7]            99,840\n",
       "│    │    └─HyperFunc: 3-96                   [1, 1536, 1, 1]           54,816\n",
       "│    │    └─DyReLU: 3-97                      [1, 768, 7, 7]            --\n",
       "│    │    └─Sequential: 3-98                  [1, 768, 7, 7]            8,448\n",
       "│    │    └─HyperFunc: 3-99                   [1, 1536, 1, 1]           54,816\n",
       "│    │    └─DyReLU: 3-100                     [1, 768, 7, 7]            --\n",
       "│    │    └─Sequential: 3-101                 [1, 128, 7, 7]            98,560\n",
       "│    │    └─DyReLU: 3-102                     [1, 128, 7, 7]            --\n",
       "│    │    └─DropPath: 3-103                   [1, 128, 7, 7]            --\n",
       "│    │    └─Global2Local: 3-104               [1, 128, 7, 7]            33,024\n",
       "├─Local2Global: 1-4                           [4, 1, 128]               --\n",
       "│    └─Linear: 2-13                           [4, 1, 128]               16,512\n",
       "│    └─Sequential: 2-14                       [4, 1, 128]               --\n",
       "│    │    └─Linear: 3-105                     [4, 1, 128]               16,512\n",
       "│    │    └─h_sigmoid: 3-106                  [4, 1, 128]               --\n",
       "│    └─Linear: 2-15                           [4, 1, 128]               16,512\n",
       "│    └─DropPath: 2-16                         [4, 1, 128]               --\n",
       "│    └─LayerNorm: 2-17                        [4, 1, 128]               256\n",
       "├─MergeClassifier: 1-5                        [1, 1000]                 --\n",
       "│    └─Sequential: 2-18                       [1, 768, 7, 7]            --\n",
       "│    │    └─Sequential: 3-107                 [1, 128, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-108                     [1, 768, 7, 7]            98,304\n",
       "│    │    └─BatchNorm2d: 3-109                [1, 768, 7, 7]            1,536\n",
       "│    └─DyReLU: 2-19                           [1, 768, 7, 7]            --\n",
       "│    │    └─ReLU6: 3-110                      [1, 768, 7, 7]            --\n",
       "│    └─Sequential: 2-20                       [1, 768, 1, 1]            --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-111          [1, 768, 1, 1]            --\n",
       "│    │    └─h_swish: 3-112                    [1, 768, 1, 1]            --\n",
       "│    └─Sequential: 2-21                       [1, 1280]                 --\n",
       "│    │    └─Linear: 3-113                     [1, 1280]                 1,148,160\n",
       "│    │    └─BatchNorm1d: 3-114                [1, 1280]                 2,560\n",
       "│    │    └─h_swish: 3-115                    [1, 1280]                 --\n",
       "│    └─Sequential: 2-22                       --                        --\n",
       "│    └─Sequential: 2-23                       [1, 1000]                 --\n",
       "│    │    └─Dropout: 3-116                    [1, 1280]                 --\n",
       "│    │    └─Linear: 3-117                     [1, 1000]                 1,281,000\n",
       "===============================================================================================\n",
       "Total params: 4,585,252\n",
       "Trainable params: 4,585,252\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 88.38\n",
       "===============================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 34.19\n",
       "Params size (MB): 18.34\n",
       "Estimated Total Size (MB): 53.13\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 3, 224, 224), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mobile_former_96m 96.817488 dw  \n",
    "mobile_former_96m 95.488608 sepdw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('micronet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e77001b71006d8f854d0c1c1be07c37466eb335b95db7122afee0467cef2cfaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
